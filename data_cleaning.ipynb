{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# groundTruth ignore the third column\n",
    "# the first number is the starting frame of an eating action, the 2nd number is the ending frame of an eating action\n",
    "\n",
    "# video data is 30 frames per second (need to convert frame numbers into sample numbers)\n",
    "# sensor sampling rate is 50 Hz \n",
    "\n",
    "# ... we can synchronize two dataset by setting the last frame time to the last UNIX time stamp in IMU or EMG file.\n",
    "\n",
    "# ok, so when one second goes by, the sensors took in 50 readings (50 Hz), and in that time, the video took in 30 frames\n",
    "# so we have to divide up the 50 data points (for each sensor) amoung the 30 frames taken in that one second\n",
    "# hence why they say multiply by 50 and divide by 30 for the frame.\n",
    "# if you just divide frame number by 30, then you get seconds. (30 frames = 1 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth_Users = os.listdir(\"groundTruth\")\n",
    "MyoData_Users = os.listdir(\"MyoData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = []\n",
    "for i in range(len(MyoData_Users)):\n",
    "    if MyoData_Users[i] in groundTruth_Users:\n",
    "        user_id.append(MyoData_Users[i])\n",
    "        \n",
    "directory_clean_data = \"clean_data/\"\n",
    "if not os.path.exists(directory_clean_data):\n",
    "        os.makedirs(directory_clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(user, fork_or_spoon= 'fork'):\n",
    "    parent_path = \"MyoData/\" + user + '/' + fork_or_spoon\n",
    "    dir_list = os.listdir(parent_path)\n",
    "    EMG_txt_path = parent_path + \"/\" + dir_list[0]\n",
    "    IMU_txt_path = parent_path + \"/\" + dir_list[1]\n",
    "    video_info_path = parent_path + \"/\" + dir_list[2]\n",
    "    # get ground truth\n",
    "    ground_truth_parent_path = \"groundTruth/\" + user + '/' + fork_or_spoon\n",
    "    ground_truth_dir_list = os.listdir(ground_truth_parent_path)\n",
    "    ground_truth_path = ground_truth_parent_path + \"/\" + ground_truth_dir_list[0]\n",
    "    return (EMG_txt_path, IMU_txt_path, video_info_path, ground_truth_path)\n",
    "\n",
    "def mul(x, y):\n",
    "    try:\n",
    "        return np.round(pd.to_numeric(x) * y)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def get_dataframe(user = \"user10\", data_for=\"EMG\", fork_or_spoon=\"fork\"):\n",
    "    paths = get_paths(user, fork_or_spoon)\n",
    "    if data_for == \"EMG\":\n",
    "        df = pd.read_csv(paths[0], sep=\",\", header=None)\n",
    "        df.columns = ['UNIX time stamp', 'EMG 1', 'EMG 2', 'EMG 3', 'EMG 4', 'EMG 5', 'EMG 6', 'EMG 7', 'EMG 8']\n",
    "        return df.assign(eating=False)\n",
    "    elif( data_for == \"IMU\"):\n",
    "        df = pd.read_csv(paths[1], sep=\",\", header=None)\n",
    "        df.columns = ['UNIX time stamp', 'Orientation X', 'Orientation Y', 'Orientation Z', 'Orientation W', 'Accelerometer X', 'Accelerometer Y', 'Accelerometer Z', 'Gyroscope X', 'Gyroscope Y','Gyroscope Z'] \n",
    "        return df.assign(eating=False)\n",
    "    elif( data_for == \"ground_truth\"):\n",
    "        df = pd.read_csv(paths[3], sep=\",\", header=None)\n",
    "        df.columns = [\"start\",\"stop\", \"noise\"] \n",
    "        df.drop(['noise'],axis=1,inplace=True)\n",
    "        return df.applymap(lambda x: mul(x, 100/30))\n",
    "    else:\n",
    "        df = pd.read_csv(paths[2], header=None)\n",
    "        df.columns = [\"starting frame\", \"ending frame\"]\n",
    "        return df\n",
    "    \n",
    "def save_clean_data(df_ground_truth, df, name, user, fork_or_spoon=\"fork\"):\n",
    "    for index, row in df_ground_truth.iterrows():\n",
    "        eating_start = row[0] # note: maybe add one here. depends on if index at 0 or 1. I assumed 0\n",
    "        eating_stop = row[1]\n",
    "        df.loc[ eating_start:eating_stop , 'eating'] = True\n",
    "    \n",
    "\n",
    "    df_eating = df[df['eating'] == True]\n",
    "    df_not_eating = df[df['eating'] == False]\n",
    "    \n",
    "    directory = \"clean_data/\" + user + \"/\" + fork_or_spoon\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    #df_eating.to_csv(sep=',', index=False, header=False)\n",
    "    df_eating.reset_index(drop=True,inplace=True)\n",
    "    df_not_eating.reset_index(drop=True,inplace=True)\n",
    "    min_data_points = min(df_eating.shape[0], df_not_eating.shape[0])\n",
    "    df_eating = df_eating.iloc[:min_data_points]\n",
    "    df_not_eating = df_not_eating.iloc[:min_data_points]\n",
    "    \n",
    "    df_eating.to_csv(path_or_buf=directory+\"/eating_\" + name + \".txt\", sep=',')\n",
    "    df_not_eating.to_csv(path_or_buf=directory+\"/not_eating_\" + name + \".txt\", sep=',')\n",
    "    df.to_csv(path_or_buf=directory+\"/master_df\" + name + \".txt\", sep=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code takes ~2 mins to run. SO only run when necessary\n",
    "def clean_data_for_each_user():\n",
    "    \n",
    "    for user in user_id:\n",
    "        for fork_or_spoon in ['spoon','fork']:\n",
    "            try:\n",
    "                df_EMG = get_dataframe(user, data_for=\"EMG\", fork_or_spoon=fork_or_spoon)\n",
    "                df_IMU = get_dataframe(user, data_for=\"IMU\", fork_or_spoon=fork_or_spoon)\n",
    "                df_ground_truth = get_dataframe(user, data_for=\"ground_truth\", fork_or_spoon=fork_or_spoon)\n",
    "\n",
    "                save_clean_data(df_ground_truth, df_EMG, name=\"EMG\", user=user, fork_or_spoon=fork_or_spoon)\n",
    "                save_clean_data(df_ground_truth, df_IMU, name=\"IMU\", user=user, fork_or_spoon=fork_or_spoon)\n",
    "            except:\n",
    "                print(\"folder name for users don't match or error in csv for ---> \" + user)\n",
    "                print(\"removing from list of users to use in the project\")\n",
    "                user_id.remove(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"user10\"\n",
    "fork_or_spoon = 'fork'\n",
    "try:\n",
    "    df_EMG = get_dataframe(user, data_for=\"EMG\", fork_or_spoon=fork_or_spoon)\n",
    "    df_IMU = get_dataframe(user, data_for=\"IMU\", fork_or_spoon=fork_or_spoon)\n",
    "    df_ground_truth = get_dataframe(user, data_for=\"ground_truth\", fork_or_spoon=fork_or_spoon)\n",
    "\n",
    "    save_clean_data(df_ground_truth, df_EMG, name=\"EMG\", user=user, fork_or_spoon=fork_or_spoon)\n",
    "    save_clean_data(df_ground_truth, df_IMU, name=\"IMU\", user=user, fork_or_spoon=fork_or_spoon)\n",
    "except:\n",
    "    print(\"folder name for users don't match or error in csv for ---> \" + user)\n",
    "    user_id.remove(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for user27\n",
      "error for user29\n"
     ]
    }
   ],
   "source": [
    "# This code takes ~4 mins to run. SO only run when necessary\n",
    "\n",
    "clean_data_for_each_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_array = []\n",
    "# diff_EMG = []\n",
    "# diff_IMU = []\n",
    "# for user in user_id:\n",
    "#     last_row_EMG = get_dataframe(user, data_for=\"EMG\")[-1:].index[0]\n",
    "#     last_row_IMU = get_dataframe(user, data_for=\"IMU\")[-1:].index[0]\n",
    "#     diff_array.append(last_row_EMG / last_row_IMU)\n",
    "#     last_frame = get_dataframe(data_for = \"other\")['ending frame'][0]\n",
    "#     diff_EMG.append(np.abs(last_row_EMG - last_frame))\n",
    "#     diff_IMU.append(np.abs(last_row_IMU - last_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[]\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n",
      "['spoon', 'fork']\n"
     ]
    }
   ],
   "source": [
    "# used for deleting extra text files that were not in a directory\n",
    "\n",
    "# import os\n",
    "# for user in os.listdir(\"clean_data\"):\n",
    "    \n",
    "#     filelist = [ f for f in os.listdir(\"clean_data/\" + user) if f.endswith(\".txt\") ]\n",
    "#     for f in filelist:\n",
    "#         os.remove(os.path.join(\"clean_data/\" + user, f))\n",
    "# #os.remove(\"demofile.txt\")\n",
    "# for user in os.listdir(\"clean_data\"):\n",
    "#     print(os.listdir(\"clean_data/\" + user))\n",
    "\n",
    "import os\n",
    "for user in os.listdir(\"clean_data\"):\n",
    "    \n",
    "    filelist = [ f for f in os.listdir(\"clean_data/\" + user) if f.endswith(\".ipynb_checkpoints\") ]\n",
    "    for f in filelist:\n",
    "        print(user)\n",
    "        #os.remove(os.path.join(\"clean_data/\" + user, f))\n",
    "#os.remove(\"demofile.txt\")\n",
    "print(\"\\n\\n\\n\")\n",
    "for user in os.listdir(\"clean_data\"):\n",
    "    print(os.listdir(\"clean_data/\" + user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
